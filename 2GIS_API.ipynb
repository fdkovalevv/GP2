{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для обработки полученных данных\n",
    "def transform_reviews(df):\n",
    "\n",
    "    target_columns = ['general_rating', 'general_review_count','general_review_count_with_stars', 'org_rating', 'org_review_count', 'org_review_count_with_stars']\n",
    "\n",
    "    df['building_name'] = df['address'].apply(lambda x: x.get('building_name',None))\n",
    "\n",
    "\n",
    "    df[['Restaurant_name', 'Brief_description']] = (df['name'].str.split(',\\s*', n=1, expand=True).replace({None: pd.NA}))\n",
    "\n",
    "    df['postcode'] = df['address'].apply(lambda x: x.get('postcode'))\n",
    "\n",
    "    df['Count_branches'] = df['org'].apply(lambda x: x.get('branch_count'))\n",
    "\n",
    "    df['Type_of_institution'] = df['rubrics'].apply(lambda x: [d.get('name') for d in x])\n",
    "\n",
    "    df.drop(['address', 'name', 'id', 'type', 'rubrics', 'org'], axis=1, inplace=True)\n",
    "\n",
    "    # Извлекаем данные из колонки 'reviews'\n",
    "    extracted_data = []\n",
    "    for review in df['reviews']:\n",
    "        if review:\n",
    "            extracted = {col: review.get(col, None) for col in target_columns}\n",
    "        else:\n",
    "            extracted = {col: None for col in target_columns}\n",
    "        extracted_data.append(extracted)\n",
    "\n",
    "    # Создаем DataFrame из извлеченных данных\n",
    "    reviews_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Объединяем с исходным DataFrame\n",
    "    return pd.concat([df.drop(['reviews'], axis=1), reviews_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_schedule(schedule):\n",
    "    #Создадим словарь для перевода на русский язык\n",
    "    days_mapping = {\n",
    "        'Mon': 'пн', 'Tue': 'вт', 'Wed': 'ср',\n",
    "        'Thu': 'чт', 'Fri': 'пт', 'Sat': 'сб', 'Sun': 'вс'\n",
    "    }\n",
    "\n",
    "    # Если у нас нет информации о времени работы, то просто заполняем None\n",
    "    if not isinstance(schedule, dict):\n",
    "        return {'working_days': None, 'working_hours': None}\n",
    "\n",
    "    # В данном цикле мы собираем время работы для каждого из дней\n",
    "    time_groups = {}\n",
    "    for eng_day, ru_day in days_mapping.items():\n",
    "        if eng_day in schedule:\n",
    "            hours = schedule[eng_day].get('working_hours', [{}])[0]\n",
    "            time = f\"{hours.get('from', '?')}–{hours.get('to', '?')}\"\n",
    "            if time not in time_groups:\n",
    "                time_groups[time] = []\n",
    "            time_groups[time].append(ru_day)\n",
    "\n",
    "    day_ranges = []\n",
    "    for time, days in time_groups.items():\n",
    "        sorted_days = sorted(days, key=lambda x: list(days_mapping.values()).index(x))\n",
    "\n",
    "        # Объединяем последовательные дни в единые диапазоны\n",
    "        ranges = []\n",
    "        start = end = sorted_days[0]\n",
    "        for day in sorted_days[1:]:\n",
    "            if list(days_mapping.values()).index(day) == list(days_mapping.values()).index(end) + 1:\n",
    "                end = day\n",
    "            else:\n",
    "                ranges.append(f\"{start}-{end}\" if start != end else start)\n",
    "                start = end = day\n",
    "        ranges.append(f\"{start}-{end}\" if start != end else start)\n",
    "\n",
    "        day_ranges.append(f\"({', '.join(ranges)}) {time}\")\n",
    "\n",
    "    working_days = []\n",
    "    working_hours = []\n",
    "    for entry in day_ranges:\n",
    "        days_part, time_part = entry.split(') ')\n",
    "        days = days_part[1:].replace('-', '—')\n",
    "        working_days.append(days)\n",
    "        working_hours.append(time_part)\n",
    "\n",
    "    return {\n",
    "        'working_days': ', '.join(working_days),\n",
    "        'working_hours': ', '.join(working_hours)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_2GIS = os.getenv('API_2GIS')\n",
    "region_id = 32\n",
    "rubric_id = '161,162'\n",
    "BASE_URL = 'https://catalog.api.2gis.com/3.0/items'\n",
    "TOTAL_NEEDED = 15000\n",
    "PAGE_SIZE = 50\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "page = 1\n",
    "\n",
    "while len(all_data) < TOTAL_NEEDED:\n",
    "    print(f\"Обрабатываю страницу {page}...\")\n",
    "\n",
    "    params_list = [\n",
    "            {\n",
    "                'key': API_2GIS,\n",
    "                'region_id': region_id,\n",
    "                'rubric_id': rubric_id,\n",
    "                'page': page,\n",
    "                'page_size': PAGE_SIZE,\n",
    "                'fields': 'items.id,items.address'\n",
    "            },\n",
    "            {\n",
    "                'key': API_2GIS,\n",
    "                'region_id': region_id,\n",
    "                'rubric_id': rubric_id,\n",
    "                'page': page,\n",
    "                'page_size': PAGE_SIZE,\n",
    "                'fields': 'items.id,items.point'\n",
    "            },\n",
    "            {\n",
    "                'key': API_2GIS,\n",
    "                'region_id': region_id,\n",
    "                'rubric_id': rubric_id,\n",
    "                'page': page,\n",
    "                'page_size': PAGE_SIZE,\n",
    "                'fields': 'items.id,items.rubrics'\n",
    "            },\n",
    "            {\n",
    "                'key': API_2GIS,\n",
    "                'region_id': region_id,\n",
    "                'rubric_id': rubric_id,\n",
    "                'page': page,\n",
    "                'page_size': PAGE_SIZE,\n",
    "                'fields': 'items.id,items.schedule'\n",
    "            },\n",
    "            {\n",
    "                'key': API_2GIS,\n",
    "                'region_id': region_id,\n",
    "                'rubric_id': rubric_id,\n",
    "                'page': page,\n",
    "                'page_size': PAGE_SIZE,\n",
    "                'fields': 'items.id,items.reviews'\n",
    "            },\n",
    "            {\n",
    "                'key': API_2GIS,\n",
    "                'region_id': region_id,\n",
    "                'rubric_id': rubric_id,\n",
    "                'page': page,\n",
    "                'page_size': PAGE_SIZE,\n",
    "                'fields': 'items.id,items.org'\n",
    "            }\n",
    "        ]\n",
    "\n",
    "\n",
    "    response = requests.get(BASE_URL, params_list[0])\n",
    "    data = response.json()\n",
    "    items = data.get('result', {}).get('items', [])\n",
    "    data_with_features = pd.DataFrame(items)\n",
    "\n",
    "    for param in params_list[1:]:\n",
    "      response = requests.get(BASE_URL, param)\n",
    "      data = response.json()\n",
    "      items = data.get('result', {}).get('items', [])\n",
    "      df_page = pd.DataFrame(items)\n",
    "      data_with_features = data_with_features.merge(df_page[['id', param['fields'].split(',')[1].split('.')[1]]], left_on='id', right_on='id')\n",
    "\n",
    "    df_page = transform_reviews(data_with_features)\n",
    "\n",
    "    # Обработка расписания\n",
    "    schedule_data = df_page['schedule'].apply(parse_schedule)\n",
    "    df_page = pd.concat([\n",
    "        df_page.drop('schedule', axis=1),\n",
    "        pd.json_normalize(schedule_data)\n",
    "    ], axis=1)\n",
    "\n",
    "    all_data = pd.concat([all_data, df_page], ignore_index=True)\n",
    "\n",
    "    if len(all_data) >= TOTAL_NEEDED:\n",
    "        all_data = all_data.iloc[:TOTAL_NEEDED]\n",
    "        break\n",
    "\n",
    "    page += 1\n",
    "    time.sleep(0.5)\n",
    "\n",
    "all_data.drop(['full_name', 'purpose_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('2GIS_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
